{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "5df0b86b31697070662e7327922181f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Decision Trees\n",
    "\n",
    "### Concepts \n",
    "You're given a dataset of **30** elements, 15 of which belong to a positive class (denoted by `+` ) and 15 of which do not (denoted by `-`). These elements are described by two attributes, A and B, that can each have either one of two values, true or false. \n",
    "\n",
    "The diagrams below show the result of splitting the dataset by attribute: the diagram on the left hand side shows that if we split by attribute A there are 13 items of the positive class and 2 of the negative class in one branch and 2 of the positive and 13 of the negative in the other branch. The right hand side shows that if we split the data by attribute B there are 8 items of the positive class and 7 of the negative class in one branch and 7 of the positive and 8 of the negative in the other branch.\n",
    "\n",
    "<img src=\"images/decision_stump.png\">\n",
    "\n",
    "### 1) Which one of the two attributes resulted in the best split of the original data? Best split is the one with the most pure nodes.\n",
    "\n",
    "Assign `ans1` to either `\"A\"` or `\"B\"` to represent which attribute is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7f0773ccaaca4a5e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step1\n",
    "# Replace None with appropriate code\n",
    "ans1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans1 should be the string \"A\" or \"B\"\n",
    "assert type(ans1) == str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "6f717f8432b6e6dd1b00d595cc814c93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Decision Trees for Regression \n",
    "\n",
    "In this section, you will use decision trees to fit a regression model to the Combined Cycle Power Plant dataset. \n",
    "\n",
    "This dataset is from the UCI ML Dataset Repository, and has been included in the `data` folder of this repository as a csv `.csv` file, `Folds5x2_pp.csv`. \n",
    "\n",
    "The features of this dataset consist of hourly average ambient variables taken from various sensors located around a power plant that record the ambient variables every second.  \n",
    "- Temperature (AT) \n",
    "- Ambient Pressure (AP) \n",
    "- Relative Humidity (RH)\n",
    "- Exhaust Vacuum (V) \n",
    "\n",
    "The target to predict is the net hourly electrical energy output (PE). \n",
    "\n",
    "The features and target variables are not normalized.\n",
    "\n",
    "In the cells below, we import `pandas` and `numpy` for you, and we load the data into a pandas DataFrame. We also include code to inspect the first five rows and get the shape of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "690aba12948e0d62fa75104e68337bf3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Load the data\n",
    "filename = 'Folds5x2_pp.csv'\n",
    "df = pd.read_csv(filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "4f8da90fd28c171bbed03778e3ada396",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "1c7641f4553750489b2ba012f301ed53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "2d0f089a2ea3e45c458b7060347f086b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below, we split the data into features and target ('PE') for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "1bdaebd958d14fe61f0549b95d7c56db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "X = df[df.columns.difference(['PE'])]\n",
    "y = df['PE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "908f11d6d829a74be4edbeead7a738b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2) Use `train_test_split` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)) to split the data into training and test sets. Create training and test sets with `test_size=0.5` and `random_state=1`.\n",
    "\n",
    "You will need to import the relevant code from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "0d38786c25982cb53f9a4a1b6e96c717",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step2\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# Import the relevant function\n",
    "None\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train and X_test should be dataframes\n",
    "assert type(X_train) == pd.DataFrame and type(X_test) == pd.DataFrame\n",
    "\n",
    "# y_train and y_test should be series\n",
    "assert type(y_train) == pd.Series and type(y_test) == pd.Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "78f78331a39a90e83268b36227be87e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3) Fit a decision tree regression model with scikit-learn to the training data. Use parameter defaults and `random_state=1` for this model\n",
    "\n",
    "For the rest of this section feel free to refer to the scikit-learn documentation on [decision tree regressors](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html).\n",
    "NOTE: This is the regression verison not the classifier.\n",
    "\n",
    "You will need to import the relevant code from scikit-learn\n",
    "\n",
    "Assign your regressor (model) to the variable `dt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "a9209fbe3444034fdaa3f956a506fbff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step3\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# Import the relevant class\n",
    "None\n",
    "\n",
    "# Instantiate the model\n",
    "dt = None\n",
    "\n",
    "# Fit the model to the training data here\n",
    "None\n",
    "\n",
    "# Testing out the model's r2 score on the training data overall\n",
    "dt_train_score = dt.score(X_train, y_train)\n",
    "dt_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt should be a decision tree regressor\n",
    "assert type(dt) == DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "5744bc1e50417bfa6dd81742aa693b96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4) That score looks good, but are we overfitting? Obtain the cross-validated coefficient of determination (r2 score) of the predictions of `dt` on the training data\n",
    "\n",
    "You can use the default `cv` value of 5, and you do not need to specify a custom scorer, since r2 is the default for a `DecisionTreeRegressor`\n",
    "\n",
    "You will need to import the relevant code from scikit-learn\n",
    "\n",
    "[cross val score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "\n",
    "[cross validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html)\n",
    "\n",
    "Assign your answer to the variable `dt_cv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "f029a5f5197e376c5c4d067faf83d300",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step4\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# Import the relevant function\n",
    "None\n",
    "\n",
    "# Assign the cross validated score to dt_cv\n",
    "dt_cv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_cv should be a NumPy array\n",
    "assert type(dt_cv) == np.ndarray\n",
    "# there should be 5 scores in dt_cv\n",
    "assert len(dt_cv) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "6eeadfaa9ac6a6f0bee921e180021d29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Hyperparameter Tuning of Decision Trees for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "9d24ef61ce500e76421d06948d486fbc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5) Create a second decision tree model, this time with the following hyperparameters specified:\n",
    " - `random_state=1`\n",
    " - `max_depth=5`\n",
    "\n",
    "### Fit it to the training data\n",
    "\n",
    "Assign the new model to the variable `dt_tuned`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "92bf6328b83bcf32a2852fb7800e594f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step5\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# Create a second decision tree model\n",
    "dt_tuned = None\n",
    "\n",
    "# Fit the new model on the training data\n",
    "None\n",
    "\n",
    "# Testing out the model's r2 score on the training data overall\n",
    "dt_tuned_train_score = dt_tuned.score(X_train, y_train)\n",
    "dt_tuned_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_tuned sould be a DecisionTreeRegressor\n",
    "assert type(dt_tuned) == DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "71437920993997cd46b68b01f49f6bb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 6) Now the score on the training data overall is worse, but how does this generalize to unseen data? Obtain the cross-validated coefficient of determination (r2 score) of the predictions of `dt_tuned` on the training data\n",
    "\n",
    "Use the same arguments as the previous cross validation\n",
    "\n",
    "Assign your answer to the variable `dt_tuned_cv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ffea576577891e8a5cb4df641a1697d4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step6\n",
    "# Replace None with appropriate code\n",
    "dt_tuned_cv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_tuned_cv should be a NumPy array\n",
    "assert type(dt_tuned_cv) == np.ndarray\n",
    "# there should be 5 scores in dt_tuned_cv\n",
    "assert len(dt_tuned_cv) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a60ea4148c5f92ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes:\n",
    "print(\"Train score for dt:      \", dt_train_score)\n",
    "print(\"Train score for dt_tuned:\", dt_tuned_train_score)\n",
    "print()\n",
    "print(\"CV scores for dt:      \", dt_cv.mean())\n",
    "print(\"CV scores for dt_tuned:\", dt_tuned_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6f918d42a2a505a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 7) Assuming you want a generalizable model that will perform well on future, unseen data, which model has better performance?  \n",
    "\n",
    "Assign `ans7` to either `\"dt\"` or `\"dt_tuned\"` to represent which model is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-feffc934dc6415f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step7\n",
    "ans7 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(ans7) == str\n",
    "assert ans7 in ['dt', 'dt_tuned']"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
